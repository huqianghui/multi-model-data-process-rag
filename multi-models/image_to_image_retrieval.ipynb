{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3bbc9a0e",
      "metadata": {
        "id": "3bbc9a0e"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/multi_modal/image_to_image_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Image to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\n",
        "\n",
        "In this notebook, we show how to build a Image to Image retrieval using LlamaIndex with GPT4-V and CLIP.\n",
        "\n",
        "LlamaIndex Image to Image Retrieval\n",
        "\n",
        "- Images embedding index: [CLIP](https://github.com/openai/CLIP) embeddings from OpenAI for images\n",
        "\n",
        "\n",
        "Framework: [LlamaIndex](https://github.com/run-llama/llama_index)\n",
        "\n",
        "Steps:\n",
        "1. Download texts, images, pdf raw files from Wikipedia pages\n",
        "\n",
        "2. Build Multi-Modal index and vetor store for both texts and images\n",
        "\n",
        "3. Retrieve relevant images given a image query using Multi-Modal Retriever\n",
        "\n",
        "4. Using GPT4V for reasoning the correlations between the input image and retrieved images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc691ca8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc691ca8",
        "outputId": "b82cedcc-ff73-47fc-f02e-bfb0b0a8510b"
      },
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/run-llama/llama_index.git\n",
        "%pip install ftfy regex tqdm\n",
        "%pip install git+https://github.com/openai/CLIP.git\n",
        "%pip install torch torchvision\n",
        "%pip install matplotlib scikit-image\n",
        "%pip install -U qdrant_client\n",
        "%pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e648a24e",
      "metadata": {
        "id": "e648a24e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_TOKEN = \"sk-...\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7683e4ed",
      "metadata": {
        "id": "7683e4ed"
      },
      "source": [
        "## Download images and texts from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad236c12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad236c12",
        "outputId": "cb600c30-9609-41c8-db9b-439e78271b84"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "image_path = Path(\"mixed_wiki\")\n",
        "image_uuid = 0\n",
        "# image_metadata_dict stores images metadata including image uuid, filename and path\n",
        "image_metadata_dict = {}\n",
        "MAX_IMAGES_PER_WIKI = 30\n",
        "\n",
        "wiki_titles = [\n",
        "    \"Vincent van Gogh\",\n",
        "    \"San Francisco\",\n",
        "    \"Batman\",\n",
        "    \"iPhone\",\n",
        "    \"Tesla Model S\",\n",
        "    \"BTS band\",\n",
        "]\n",
        "\n",
        "# create folder for images only\n",
        "if not image_path.exists():\n",
        "    Path.mkdir(image_path)\n",
        "\n",
        "\n",
        "# Download images for wiki pages\n",
        "# Assign UUID for each image\n",
        "for title in wiki_titles:\n",
        "    images_per_wiki = 0\n",
        "    print(title)\n",
        "    try:\n",
        "        page_py = wikipedia.page(title)\n",
        "        list_img_urls = page_py.images\n",
        "        for url in list_img_urls:\n",
        "            if url.endswith(\".jpg\") or url.endswith(\".png\"):\n",
        "                image_uuid += 1\n",
        "                image_file_name = title + \"_\" + url.split(\"/\")[-1]\n",
        "\n",
        "                # img_path could be s3 path pointing to the raw image file in the future\n",
        "                image_metadata_dict[image_uuid] = {\n",
        "                    \"filename\": image_file_name,\n",
        "                    \"img_path\": \"./\" + str(image_path / f\"{image_uuid}.jpg\"),\n",
        "                }\n",
        "                urllib.request.urlretrieve(\n",
        "                    url, image_path / f\"{image_uuid}.jpg\"\n",
        "                )\n",
        "                images_per_wiki += 1\n",
        "                # Limit the number of images downloaded per wiki page to 15\n",
        "                if images_per_wiki > MAX_IMAGES_PER_WIKI:\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(str(Exception(\"No images found for Wikipedia page: \")) + title)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efb1f7e",
      "metadata": {
        "id": "2efb1f7e"
      },
      "source": [
        "### Plot images from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a64bb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "e5a64bb6",
        "outputId": "1434a078-7cab-4c2f-b68b-57753bd302ba"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "image_paths = []\n",
        "for img_path in os.listdir(\"./mixed_wiki\"):\n",
        "    image_paths.append(str(os.path.join(\"./mixed_wiki\", img_path)))\n",
        "\n",
        "\n",
        "def plot_images(image_paths):\n",
        "    images_shown = 0\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    for img_path in image_paths:\n",
        "        if os.path.isfile(img_path):\n",
        "            image = Image.open(img_path)\n",
        "\n",
        "            plt.subplot(5, 5, images_shown + 1)\n",
        "            plt.imshow(image)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "\n",
        "            images_shown += 1\n",
        "            if images_shown >= 25:\n",
        "                break\n",
        "\n",
        "\n",
        "plot_images(image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f476d8a",
      "metadata": {
        "id": "4f476d8a"
      },
      "source": [
        "## Build Multi-Modal index and Vector Store to index both text and images from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d13318",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90d13318",
        "outputId": "ff7966fa-6527-4cb2-ebbd-4fe600e37224"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\n",
        "from llama_index.vector_stores import QdrantVectorStore\n",
        "from llama_index import SimpleDirectoryReader, StorageContext\n",
        "\n",
        "import qdrant_client\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "\n",
        "\n",
        "# Create a local Qdrant vector store\n",
        "client = qdrant_client.QdrantClient(path=\"qdrant_img_db\")\n",
        "\n",
        "text_store = QdrantVectorStore(\n",
        "    client=client, collection_name=\"text_collection\"\n",
        ")\n",
        "image_store = QdrantVectorStore(\n",
        "    client=client, collection_name=\"image_collection\"\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=text_store,image_store=image_store)\n",
        "\n",
        "# Create the MultiModal index\n",
        "documents = SimpleDirectoryReader(\"./mixed_wiki/\").load_data()\n",
        "index = MultiModalVectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6f7ab8",
      "metadata": {
        "id": "9b6f7ab8"
      },
      "source": [
        "## Retrieve images from Multi-Modal Index using an image as the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "natyRFRJQvnY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "natyRFRJQvnY",
        "outputId": "ff59f4b5-22dd-48b7-c176-ed6657144176"
      },
      "outputs": [],
      "source": [
        "# Download a copy of Starry Night by Van Gogh\n",
        "!wget \"https://www.dropbox.com/scl/fi/2rqf4z8pfb8v0kw0qvp3b/starry_night.jpg?rlkey=kk83702lzlu0zh0a47lle3h10&dl=0\" -O starry_night.jpg -q\n",
        "input_image = \"./starry_night.jpg\"\n",
        "plot_images([input_image])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815a140b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "815a140b",
        "outputId": "0372b216-bd80-47c0-aebb-87be978a273d"
      },
      "outputs": [],
      "source": [
        "# instantiate a retriever\n",
        "retriever_engine = index.as_retriever(image_similarity_top_k=4)\n",
        "# get images semantically similar to our own\n",
        "retrieval_results = retriever_engine.image_to_image_retrieve(\n",
        "    \"./starry_night.jpg\"\n",
        ")\n",
        "retrieved_images = []\n",
        "for res in retrieval_results:\n",
        "    retrieved_images.append(res.node.metadata[\"file_path\"])\n",
        "\n",
        "# display the images we found\n",
        "plot_images(retrieved_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xAues6eRMTNr",
      "metadata": {
        "id": "xAues6eRMTNr"
      },
      "source": [
        "## Query the index using an image and a prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Od7GKfx1wrOD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od7GKfx1wrOD",
        "outputId": "32ddd60d-1cf2-4eb6-b0e5-871216e57cd9"
      },
      "outputs": [],
      "source": [
        "from llama_index.prompts import PromptTemplate\n",
        "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
        "\n",
        "openai_mm_llm = OpenAIMultiModal(\n",
        "    model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500\n",
        ")\n",
        "\n",
        "qa_tmpl_str = (\n",
        "    \"Given the images provided, respond to the prompt.\\n\"\n",
        "    \"Prompt: {query_str}\\n\"\n",
        "    \"Response: \"\n",
        ")\n",
        "\n",
        "qa_tmpl = PromptTemplate(qa_tmpl_str)\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    multi_modal_llm=openai_mm_llm, image_qa_template=qa_tmpl,\n",
        "    similarity_top_k=3, image_similarity_top_k=3\n",
        ")\n",
        "\n",
        "query_str = \"Tell me more about paintings like this\"\n",
        "response = query_engine.image_query(\"./starry_night.jpg\", query_str)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
